{"ast":null,"code":"import { FILE_STATES, logger } from \"@rpldy/shared\";\nimport processBatchItems from \"./processBatchItems\";\nimport { getBatchDataFromItemId, getIsItemBatchReady, isNewBatchStarting, cancelBatchForItem, loadNewBatchForItem, isItemBelongsToBatch } from \"./batchHelpers\";\n\nvar getIsItemInActiveRequest = function getIsItemInActiveRequest(queue, itemId) {\n  return !!~queue.getState().activeIds // $FlowFixMe - no flat\n  .flat().indexOf(itemId);\n};\n\nvar getIsItemReady = function getIsItemReady(item) {\n  return item.state === FILE_STATES.ADDED;\n};\n\nexport var findNextItemIndex = function findNextItemIndex(queue) {\n  var state = queue.getState(),\n      itemQueue = state.itemQueue,\n      items = state.items;\n  var index = 0,\n      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a \"ready\" batch\n\n  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !getIsItemBatchReady(queue, nextId) || !getIsItemReady(items[nextId]))) {\n    index += 1;\n    nextId = itemQueue[index];\n  }\n\n  return nextId ? index : -1;\n};\nexport var getNextIdGroup = function getNextIdGroup(queue) {\n  var itemQueue = queue.getState().itemQueue;\n  var nextItemIndex = findNextItemIndex(queue);\n  var nextId = itemQueue[nextItemIndex],\n      nextGroup;\n\n  if (nextId) {\n    var batchData = getBatchDataFromItemId(queue, nextId);\n    var batchId = batchData.batch.id,\n        groupMax = batchData.batchOptions.maxGroupSize || 0;\n\n    if (batchData.batchOptions.grouped && groupMax > 1) {\n      nextGroup = [];\n      var nextBelongsToSameBatch = true; //dont group files from different batches\n\n      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {\n        nextGroup.push(nextId);\n        nextId = itemQueue[nextItemIndex + nextGroup.length];\n        nextBelongsToSameBatch = nextId && isItemBelongsToBatch(queue, nextId, batchId);\n      }\n    } else {\n      nextGroup = [nextId];\n    }\n  }\n\n  return nextGroup;\n};\n\nvar processNext = function processNext(queue) {\n  var ids = getNextIdGroup(queue);\n  var resultP = Promise.resolve();\n\n  if (ids) {\n    var currentCount = queue.getCurrentActiveCount(),\n        _queue$getOptions = queue.getOptions(),\n        _queue$getOptions$con = _queue$getOptions.concurrent,\n        concurrent = _queue$getOptions$con === void 0 ? 0 : _queue$getOptions$con,\n        _queue$getOptions$max = _queue$getOptions.maxConcurrent,\n        maxConcurrent = _queue$getOptions$max === void 0 ? 0 : _queue$getOptions$max;\n\n    if (!currentCount || concurrent && currentCount < maxConcurrent) {\n      logger.debugLog(\"uploader.processor: Processing next upload - \", {\n        ids: ids,\n        state: queue.getState(),\n        currentCount: currentCount\n      });\n      var cancelled = false;\n      var newBatchP = Promise.resolve(false);\n\n      if (isNewBatchStarting(queue, ids[0])) {\n        newBatchP = loadNewBatchForItem(queue, ids[0]).then(function (allowBatch) {\n          cancelled = !allowBatch;\n\n          if (cancelled) {\n            cancelBatchForItem(queue, ids[0]);\n            processNext(queue);\n          }\n\n          return cancelled;\n        });\n      }\n\n      resultP = newBatchP.then(function (cancelled) {\n        if (!cancelled) {\n          processBatchItems(queue, ids, processNext);\n        }\n      });\n    }\n  }\n\n  return resultP;\n};\n\nexport default processNext;","map":{"version":3,"sources":["/home/user/Desktop/react_board/boards/boards-ui/node_modules/@rpldy/uploader/lib/esm/queue/processQueueNext.js"],"names":["FILE_STATES","logger","processBatchItems","getBatchDataFromItemId","getIsItemBatchReady","isNewBatchStarting","cancelBatchForItem","loadNewBatchForItem","isItemBelongsToBatch","getIsItemInActiveRequest","queue","itemId","getState","activeIds","flat","indexOf","getIsItemReady","item","state","ADDED","findNextItemIndex","itemQueue","items","index","nextId","getNextIdGroup","nextItemIndex","nextGroup","batchData","batchId","batch","id","groupMax","batchOptions","maxGroupSize","grouped","nextBelongsToSameBatch","length","push","processNext","ids","resultP","Promise","resolve","currentCount","getCurrentActiveCount","getOptions","concurrent","maxConcurrent","debugLog","cancelled","newBatchP","then","allowBatch"],"mappings":"AAAA,SAASA,WAAT,EAAsBC,MAAtB,QAAoC,eAApC;AACA,OAAOC,iBAAP,MAA8B,qBAA9B;AACA,SAASC,sBAAT,EAAiCC,mBAAjC,EAAsDC,kBAAtD,EAA0EC,kBAA1E,EAA8FC,mBAA9F,EAAmHC,oBAAnH,QAA+I,gBAA/I;;AAEA,IAAMC,wBAAwB,GAAG,SAA3BA,wBAA2B,CAACC,KAAD,EAAQC,MAAR,EAAmB;AAClD,SAAO,CAAC,CAAC,CAACD,KAAK,CAACE,QAAN,GAAiBC,SAAjB,CAA2B;AAA3B,GACTC,IADS,GACFC,OADE,CACMJ,MADN,CAAV;AAED,CAHD;;AAKA,IAAMK,cAAc,GAAG,SAAjBA,cAAiB,CAAAC,IAAI;AAAA,SAAIA,IAAI,CAACC,KAAL,KAAelB,WAAW,CAACmB,KAA/B;AAAA,CAA3B;;AAEA,OAAO,IAAMC,iBAAiB,GAAG,SAApBA,iBAAoB,CAAAV,KAAK,EAAI;AACxC,MAAMQ,KAAK,GAAGR,KAAK,CAACE,QAAN,EAAd;AAAA,MACMS,SAAS,GAAGH,KAAK,CAACG,SADxB;AAAA,MAEMC,KAAK,GAAGJ,KAAK,CAACI,KAFpB;AAGA,MAAIC,KAAK,GAAG,CAAZ;AAAA,MACIC,MAAM,GAAGH,SAAS,CAACE,KAAD,CADtB,CAJwC,CAKT;;AAE/B,SAAOC,MAAM,KAAKf,wBAAwB,CAACC,KAAD,EAAQc,MAAR,CAAxB,IAA2C,CAACpB,mBAAmB,CAACM,KAAD,EAAQc,MAAR,CAA/D,IAAkF,CAACR,cAAc,CAACM,KAAK,CAACE,MAAD,CAAN,CAAtG,CAAb,EAAqI;AACnID,IAAAA,KAAK,IAAI,CAAT;AACAC,IAAAA,MAAM,GAAGH,SAAS,CAACE,KAAD,CAAlB;AACD;;AAED,SAAOC,MAAM,GAAGD,KAAH,GAAW,CAAC,CAAzB;AACD,CAbM;AAcP,OAAO,IAAME,cAAc,GAAG,SAAjBA,cAAiB,CAAAf,KAAK,EAAI;AACrC,MAAMW,SAAS,GAAGX,KAAK,CAACE,QAAN,GAAiBS,SAAnC;AACA,MAAMK,aAAa,GAAGN,iBAAiB,CAACV,KAAD,CAAvC;AACA,MAAIc,MAAM,GAAGH,SAAS,CAACK,aAAD,CAAtB;AAAA,MACIC,SADJ;;AAGA,MAAIH,MAAJ,EAAY;AACV,QAAMI,SAAS,GAAGzB,sBAAsB,CAACO,KAAD,EAAQc,MAAR,CAAxC;AACA,QAAMK,OAAO,GAAGD,SAAS,CAACE,KAAV,CAAgBC,EAAhC;AAAA,QACMC,QAAQ,GAAGJ,SAAS,CAACK,YAAV,CAAuBC,YAAvB,IAAuC,CADxD;;AAGA,QAAIN,SAAS,CAACK,YAAV,CAAuBE,OAAvB,IAAkCH,QAAQ,GAAG,CAAjD,EAAoD;AAClDL,MAAAA,SAAS,GAAG,EAAZ;AACA,UAAIS,sBAAsB,GAAG,IAA7B,CAFkD,CAEf;;AAEnC,aAAOT,SAAS,CAACU,MAAV,GAAmBL,QAAnB,IAA+BI,sBAAtC,EAA8D;AAC5DT,QAAAA,SAAS,CAACW,IAAV,CAAed,MAAf;AACAA,QAAAA,MAAM,GAAGH,SAAS,CAACK,aAAa,GAAGC,SAAS,CAACU,MAA3B,CAAlB;AACAD,QAAAA,sBAAsB,GAAGZ,MAAM,IAAIhB,oBAAoB,CAACE,KAAD,EAAQc,MAAR,EAAgBK,OAAhB,CAAvD;AACD;AACF,KATD,MASO;AACLF,MAAAA,SAAS,GAAG,CAACH,MAAD,CAAZ;AACD;AACF;;AAED,SAAOG,SAAP;AACD,CA1BM;;AA4BP,IAAMY,WAAW,GAAG,SAAdA,WAAc,CAAA7B,KAAK,EAAI;AAC3B,MAAM8B,GAAG,GAAGf,cAAc,CAACf,KAAD,CAA1B;AACA,MAAI+B,OAAO,GAAGC,OAAO,CAACC,OAAR,EAAd;;AAEA,MAAIH,GAAJ,EAAS;AACD,QAAAI,YAAY,GAAGlC,KAAK,CAACmC,qBAAN,EAAf;AAAA,4BAIFnC,KAAK,CAACoC,UAAN,EAJE;AAAA,kDAEJC,UAFI;AAAA,QAEJA,UAFI,sCAES,CAFT;AAAA,kDAGJC,aAHI;AAAA,QAGJA,aAHI,sCAGY,CAHZ;;AAMN,QAAI,CAACJ,YAAD,IAAiBG,UAAU,IAAIH,YAAY,GAAGI,aAAlD,EAAiE;AAC/D/C,MAAAA,MAAM,CAACgD,QAAP,CAAgB,+CAAhB,EAAiE;AAC/DT,QAAAA,GAAG,EAAHA,GAD+D;AAE/DtB,QAAAA,KAAK,EAAER,KAAK,CAACE,QAAN,EAFwD;AAG/DgC,QAAAA,YAAY,EAAZA;AAH+D,OAAjE;AAKA,UAAIM,SAAS,GAAG,KAAhB;AACA,UAAIC,SAAS,GAAGT,OAAO,CAACC,OAAR,CAAgB,KAAhB,CAAhB;;AAEA,UAAItC,kBAAkB,CAACK,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAtB,EAAuC;AACrCW,QAAAA,SAAS,GAAG5C,mBAAmB,CAACG,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAnB,CAAmCY,IAAnC,CAAwC,UAAAC,UAAU,EAAI;AAChEH,UAAAA,SAAS,GAAG,CAACG,UAAb;;AAEA,cAAIH,SAAJ,EAAe;AACb5C,YAAAA,kBAAkB,CAACI,KAAD,EAAQ8B,GAAG,CAAC,CAAD,CAAX,CAAlB;AACAD,YAAAA,WAAW,CAAC7B,KAAD,CAAX;AACD;;AAED,iBAAOwC,SAAP;AACD,SATW,CAAZ;AAUD;;AAEDT,MAAAA,OAAO,GAAGU,SAAS,CAACC,IAAV,CAAe,UAAAF,SAAS,EAAI;AACpC,YAAI,CAACA,SAAL,EAAgB;AACdhD,UAAAA,iBAAiB,CAACQ,KAAD,EAAQ8B,GAAR,EAAaD,WAAb,CAAjB;AACD;AACF,OAJS,CAAV;AAKD;AACF;;AAED,SAAOE,OAAP;AACD,CA1CD;;AA4CA,eAAeF,WAAf","sourcesContent":["import { FILE_STATES, logger } from \"@rpldy/shared\";\nimport processBatchItems from \"./processBatchItems\";\nimport { getBatchDataFromItemId, getIsItemBatchReady, isNewBatchStarting, cancelBatchForItem, loadNewBatchForItem, isItemBelongsToBatch } from \"./batchHelpers\";\n\nconst getIsItemInActiveRequest = (queue, itemId) => {\n  return !!~queue.getState().activeIds // $FlowFixMe - no flat\n  .flat().indexOf(itemId);\n};\n\nconst getIsItemReady = item => item.state === FILE_STATES.ADDED;\n\nexport const findNextItemIndex = queue => {\n  const state = queue.getState(),\n        itemQueue = state.itemQueue,\n        items = state.items;\n  let index = 0,\n      nextId = itemQueue[index]; //find item that isnt already in an active request and belongs to a \"ready\" batch\n\n  while (nextId && (getIsItemInActiveRequest(queue, nextId) || !getIsItemBatchReady(queue, nextId) || !getIsItemReady(items[nextId]))) {\n    index += 1;\n    nextId = itemQueue[index];\n  }\n\n  return nextId ? index : -1;\n};\nexport const getNextIdGroup = queue => {\n  const itemQueue = queue.getState().itemQueue;\n  const nextItemIndex = findNextItemIndex(queue);\n  let nextId = itemQueue[nextItemIndex],\n      nextGroup;\n\n  if (nextId) {\n    const batchData = getBatchDataFromItemId(queue, nextId);\n    const batchId = batchData.batch.id,\n          groupMax = batchData.batchOptions.maxGroupSize || 0;\n\n    if (batchData.batchOptions.grouped && groupMax > 1) {\n      nextGroup = [];\n      let nextBelongsToSameBatch = true; //dont group files from different batches\n\n      while (nextGroup.length < groupMax && nextBelongsToSameBatch) {\n        nextGroup.push(nextId);\n        nextId = itemQueue[nextItemIndex + nextGroup.length];\n        nextBelongsToSameBatch = nextId && isItemBelongsToBatch(queue, nextId, batchId);\n      }\n    } else {\n      nextGroup = [nextId];\n    }\n  }\n\n  return nextGroup;\n};\n\nconst processNext = queue => {\n  const ids = getNextIdGroup(queue);\n  let resultP = Promise.resolve();\n\n  if (ids) {\n    const currentCount = queue.getCurrentActiveCount(),\n          {\n      concurrent = 0,\n      maxConcurrent = 0\n    } = queue.getOptions();\n\n    if (!currentCount || concurrent && currentCount < maxConcurrent) {\n      logger.debugLog(\"uploader.processor: Processing next upload - \", {\n        ids,\n        state: queue.getState(),\n        currentCount\n      });\n      let cancelled = false;\n      let newBatchP = Promise.resolve(false);\n\n      if (isNewBatchStarting(queue, ids[0])) {\n        newBatchP = loadNewBatchForItem(queue, ids[0]).then(allowBatch => {\n          cancelled = !allowBatch;\n\n          if (cancelled) {\n            cancelBatchForItem(queue, ids[0]);\n            processNext(queue);\n          }\n\n          return cancelled;\n        });\n      }\n\n      resultP = newBatchP.then(cancelled => {\n        if (!cancelled) {\n          processBatchItems(queue, ids, processNext);\n        }\n      });\n    }\n  }\n\n  return resultP;\n};\n\nexport default processNext;"]},"metadata":{},"sourceType":"module"}